
[toc]

---

**写在最前面**  
github的markdown不支持LaTeX，所以公式没法显示出来。有需求可自行下载源文件到支持LaTeX的编辑器中看，效果更佳

---

# CS基础

## 计算机组成原理 

## 操作系统 

## 数据结构和算法

## 计算机网络

## 编程语言

### C

### python

---
# 网络空间安全

## 系统安全

## web安全
### Redos

**Regular expression Denial of Service (ReDoS)是一种利用程序实现时采用了不安全的正则表达式，从而构造特定输入引起DOS拒绝服务的一种攻击手段。**

#### 预备知识
__Regex与DFA、NFA__  
> 不想看原理可以直接跳过去看例子，部分人可秒懂

正则表达式，又称规则表达式，英文名为Regular Expression，在代码中常简写为regex、regexp或RE，是计算机科学的一个概念。

正则表通常被用来检索、替换那些符合某个模式(规则)的文本。

正则表达式是对字符串（包括普通字符（例如，a 到 z 之间的字母）和特殊字符（称为“元字符”））操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。

正则表达式是一种文本模式，模式描述在搜索文本时要匹配的一个或多个字符串。

DFA 引擎在线性时状态下执行，因为它们不要求回溯（并因此它们永远不测试相同的字符两次）。
DFA 引擎还可以确保匹配最长的可能的字符串。
但是，因为 DFA 引擎只包含有限的状态，所以它不能匹配具有反向引用的模式；并且因为它不构造显示扩展，所以它不可以捕获子表达式。
传统的 NFA 引擎运行所谓的“贪婪的”匹配回溯算法，以指定顺序测试正则表达式的所有可能的扩展并接受第一个匹配项。
因为传统的 NFA 构造正则表达式的特定扩展以获得成功的匹配，所以它可以捕获子表达式匹配和匹配的反向引用。
但是，因为传统的 NFA 回溯，所以它可以访问完全相同的状态多次（如果通过不同的路径到达该状态）。
因此，在最坏情况下，它的执行速度可能非常慢。因为传统的 NFA 接受它找到的第一个匹配，所以它还可能会导致其他（可能更长）匹配未被发现。

POSIX NFA 引擎与传统的 NFA 引擎类似。
不同的一点在于：在它们可以确保已找到了可能的最长的匹配之前，它们将继续回溯。
因此，POSIX NFA 引擎的速度慢于传统的 NFA 引擎；并且在使用 POSIX NFA 时，您恐怕不会愿意在更改回溯搜索的顺序的情况下来支持较短的匹配搜索，而非较长的匹配搜索。

* 使用DFA引擎的程序主要有：awk,egrep,flex,lex,MySQL,Procmail等；
* 使用传统型NFA引擎的程序主要有：GNU Emacs,Java,ergp,less,more,.NET语言,PCRE library,Perl,PHP,Python,Ruby,sed,vi；
* 使用POSIX NFA引擎的程序主要有：mawk,Mortice Kern Systems’ utilities,GNU Emacs(使用时可以明确指定)；
* 也有使用DFA/NFA混合的引擎：GNU awk,GNU grep/egrep,Tcl。

**下面用实例来说明正则匹配时，NFA与DFA引擎的区别：**
``` shell
   字符串： hello regextest
   正则表达式：  \reg(axtest|extext|extest)
```
`DFA`：拿着字符串文本去匹配正则表达式。
hello没有正则匹配的，去掉，reg匹配上了，继续；exte和第二、三分支匹配，继续；st和第三分支匹配，至此，regextest匹配成功，结束。过程中字符串只遍历了一次。

`NFA`：拿着正则表达式去对比字符串文本。
r->淘汰hello，匹配到r，e->e，g->g，a->e失败，回溯到上一个匹配的g，匹配下一个正则，e->e，x->x，t->t，e->e，x->s失败，回溯到上一个匹配的e，匹配下一个正则，s->s，t->t，匹配成功，结束。过程中字符串遍历了多次。

__DOS__  
**DOS攻击**这里引用段子嘎的介绍：
DoS（Denial of Service，拒绝服务）是一种网络攻击手段，通过大量合法的请求占用大量网络资源，以达到瘫痪网络的目的。
形象一点的比喻是，你开了一家小面馆，黑客派了几个广场的大爷大妈涌入你的店里坐着吹空调，也不消费就霸着场子，导致其他顾客根本无法进店消费。
想详细了解可自行去查资料。

<br>

> 下面开始介绍本文重点：ReDos
#### 原理
本文主要介绍使用NFA引擎的程序语言，使用DFA引擎的程序不存在ReDos。因为NFA引擎的回溯机制，导致了当字符串文本与正则表达式不匹配时，所花费的时间要比匹配时长的多。
简单点说，确定匹配成功就不做了，但是要确定匹配失败，则需要与所有可能的路径进行对比匹配，都证明匹配不了，才能确定匹配失败。

此时，如果使用简单的非分组正则表达式来进行匹配，也不会引起问题，例如：

```
 ^\d+$
```
+ 1）23x
23,`x`　　2,`3x`	　　`23x`
标粗部分为确认不匹配的部分，第一次遇到不匹配时回溯到上一个继续进行匹配，共`3`次

+ 2）123x
123,`x`　　12,`3x`　　1,`23x`　　`123x`
标粗部分为确认不匹配的部分，第一次遇到不匹配时回溯到上一个继续进行匹配，共`4`次

此时呈`线性`增长。

但是，如果使用重复性分组正则表达式来进行匹配，则可能引起问题，例如：
```
 ^\(d+)+$
```
+ 1）23x
23,`x`　　2,3,`x`　　2,`3x`	　　`23x`
标粗部分为确认不匹配的部分，迭代多次才能确认原字符串不匹配，总共需要`2^2 = 4`次

+ 2）123x
123,`x`　　12,3,`x`　　12,`3x`　　1,23,`x`　　1,2,3,`x`　　1,2,`3x`　　1,`23x`　　`123x`
标粗部分为确认不匹配的部分，迭代多次才能确认原字符串不匹配，总共需要`2^3 = 8`次

此时呈`指数`增长。

<br>

#### 验证
``` python
# coding:utf-8

import time
import re

strs = (
    '1234567890x',
    '12345678901234567890x',
    '1234567890123456789012345x',
    '12345678901234567890123456x',
    '123456789012345678901234567x',
    '1234567890123456789012345678x',
    '12345678901234567890123456789x'
)
regex = '^(\d+)+$'

def fun(strs, regex):
    t1 = time.time()
    result = re.compile(regex).match(strs)
    t2 = time.time()
    print("%s : %s : %.2f" % (strs, str(result), (t2 - t1)))

for s in strs:
    fun(s, regex)
```

运行结果：
```
C:\Python\Python36\python.exe D:/python/get_hi3ms_user_files/redos/redos.py
1234567890x : None : 0.00
12345678901234567890x : None : 0.09
1234567890123456789012345x : None : 2.95
12345678901234567890123456x : None : 5.92
123456789012345678901234567x : None : 12.51
1234567890123456789012345678x : None : 24.68
12345678901234567890123456789x : None : 52.39

Process finished with exit code 0
```
可以看出每增加一位，其运行时间呈现**指数**增长。

再来查看运行时的CPU占用，测试机子为4核电脑，单进程跑，CPU25%，单核占满了。
<img src="/assets/blogimg/security/redos-1.png" />

同时运行4个程序就能跑满100%CPU，可造成拒绝服务。
<img src="/assets/blogimg/security/redos-2.png" />

#### 影响
容易引起ReDos的正则表达式主要有两类：
1、	包含具有自我重复的重复性分组的正则，例如：
``` bash
^(\d+)+$
^(\d*)*$
^(\d+)*$
^(\d+|\s+)*$
…
```
2、	包含替换的重复性分组，例如：
``` bash
^(\d|\d|\d)+$
^(\d|\d?)+$
…
```
目前已经在使用的，甚至是一些官方提供的正则表达式，也可能存在缺陷：

1、	[正则表达式库网站中，提供的专门用于验证电子邮件的正则](（http://regexlib.com/REDetails.aspx?regexp_id=1757&AspxAutoDetectCookieSupport=1）)
```
/^([a-zA-Z0-9])(([\-.]|[_]+)?([a-zA-Z0-9]+))*(@){1}[a-z0-9]+[.]{1}(([a-z]{2,3})|([a-z]{2,3}[.]{1}[a-z]{2,3}))$/
```
输入：aaaaaaaaaaaaaaaaaaaaaaaa!

2、	[OWASP验证正则表达式库](https://www.owasp.org/index.php/OWASP_Validation_Regex_Repository)，这也是一个有缺陷的正则：
```
^(([a-z])+.)+[A-Z]([a-z])+$
```
输入：aaaaaaaaaaaaaaaaaaaaaaaa!

3、	常用的：
多个邮箱地址验证
```
^[a-zA-Z]+(([\'\,\.\-][a-zA-Z ])?[a-zA-Z]*)*\s+&lt;(\w[-._\w]*\w@\w[-._\w]*\w\.\w{2,3})&gt;$|^(\w[-._\w]*\w@\w[-._\w]*\w\.\w{2,3})$
```
输入: aaaaaaaaaaaaaaaaaaaaaaaa!

复数验证
```
^\d*[0-9](|.\d*[0-9]|)*$
```
输入: 1111111111111111111111111!

模式匹配
```
^([a-z0-9]+([\-a-z0-9]*[a-z0-9]+)?\.){0,}([a-z0-9]+([\-a-z0-9]*[a-z0-9]+)?){1,63}(\.[a-z0-9]{2,7})+$
```
输入: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa!

另外，攻击者也可能通过输入来自己构造缺陷正则，从而发起攻击：
例如：
``` java
String userName = textBox1.Text;
String password = textBox2.Text;
Regex testPassword = new Regex(userName);
match match = testPassword.Match(password);
```
此时，攻击者输入：
```
Userame：^(( [az])+.)+ [AZ]([az])+$
Password：aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa！
```
则会引起ReDos.

#### 风险因素
<img src="/assets/blogimg/security/redos-3.png" />

在web的每一层都包含有正则表达式，也就是每一层都会存在有缺陷的正则风险。
攻击者能够攻击Web浏览器（PC端或者移动端）、WAF、数据库或者是Web服务器。

#### 检测
其实理想的方法是在代码编译时用一个正则去查找匹配存在缺陷的正则表达式，然而搜索了一下，没有找到这种有效的正则。目前比较好的检测手段主要分两种。

* 一是静态代码工具分析，通过抓取代码中的正则去匹配已知的存在缺陷的特征库，重点需要检测存在分组和重复的正则，这种方法的准确率主要依赖于特征库的质量。
* 二是通过模糊测试去程序中进行检测。在使用了正则的地方不断使用多种字符串去进行输入匹配，记录下引擎在判断是否匹配时花费的时间，时间过长则很有可能存在不安全的正则。这种方法依赖于构造的字符串是否够全面。

#### 防御
目前主要的防御手段主要还是在程序中避免出现不安全的正则：

* 1、	在编写正则的时候，尽量不要使用过于复杂的正则，越复杂越容易有缺陷，且越不容易进行全面的测试；
* 2、	编写正则的时候，尽量减少分组的使用量，使用的越多出现缺陷的可能性越大
* 3、	避免动态构造正则（即new Regex(...)），如果需要构造，也保证不要使用用户的输入来进行动态构造。
* 4、	严格限制用户输入的长度限制。

服务端可以进行性能监控，暂时还没法进行有效的防御。



参考链接：
https://msdn.microsoft.com/zh-cn/magazine/ff646973.aspx
https://www.owasp.org/index.php/Regular_expression_Denial_of_Service_-_ReDoS
https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/1700215?fr=aladdin
http://www.freebuf.com/articles/network/124422.html


## 移动安全

## 企业安全
---
# AI

## 特征工程

## 常见算法及模型
### 机器学习
#### KNN
#### Naive Bayes
#### Decision Tree
#### Random Forest
#### SVM


### 深度学习
#### CNN
#### RNN
循环神经网络 Recurrent Neural Network
> 下图介绍了RNN的基本原理，图片来源于台大李宏毅教授PPT  

![RNN](https://pic4.zhimg.com/80/v2-f716c816d46792b867a6815c278f11cb_hd.jpg)  

`$x$`为当前状态下的输入  
`$h$`为收到的上一节点的输入。其中主要保存了先前节点的记忆数据  
`$y$`为当前节点的输出。通常使用`$\dot{h}$`进行映射到一个线性层，再用softmax进行分类得到结果  
`$\dot {h}$`为当前节点传给下一节点的记忆。  

__单个节点计算方式如上图，连起来就形成了RNN序列__  
![RNN](https://pic2.zhimg.com/80/v2-71652d6a1eee9def631c18ea5e3c7605_hd.jpg)  

---

##### LSTM
> Long short-term memory， 长短时记忆，RNN变种，主要可以进行选择性记忆，并且解决了一般深度神经网络中梯度消失和梯度爆炸的问题。  

![LSTM](https://pic4.zhimg.com/80/v2-e4f9851cad426dfe4ab1c76209546827_hd.jpg)  
上图把LSTM与原始RNN进行了对比。  

LSTM vs RNN：  
上图可以看出naive RNN和LSTM最大的不同在于LSTM每次都传递两个值，`$c^t$`和`$h^t$`。其中，`$c^t$`主要用于存储历史节点的记忆信息，相当于naive RNN中的`$h^t$`（因为naive RNN只有一个`$h^t$`），他们都包含了以往节点中的`记忆数据`，属于重要的信息，每次传递都会加入当前节点的内容，变化相对来说较小；而LSTM的另一个值`$h^t$`（不同于naive RNN的`$h^t$`）则主要是为了和当前输入进行运算来获得`门控信号`，本身不含记忆数据，且每次传递时因为主要由当前的输入决定，变化来说相对较大。

LSTM中`$c^t$`和`$h^t$`的计算如下图所示：  
![LSTM](https://pic2.zhimg.com/80/v2-556c74f0e025a47fea05dc0f76ea775d_hd.jpg)  

明显可以看出，LSTM中，`$c^t$`主要包含了记忆数据，`$h^t$`主要用于计算门控信号。  

_Tips:_  
`$z$`表示处理过的当前信息  
`$z^f$`、`$z^i$`、`$z^o$`: 均为使用当前输入`$x^t$`和上个节点传递的`$h^{t-1}$`进行计算得到的门控信号。其中f为forget，表遗忘门控；i为information，表记忆门控；o为output，表输出门控。

```math
z^f = \sigma(W^fX^t+b^f)  

z^i = \sigma(W^iX^t+b^i)  

z^o = \sigma(W^oX^t+b^o)  
```
其中`$\sigma$`函数代表sigmoid函数

LSTM的效果：  
1、当gate是关闭的，那么就会阻止对当前信息的改变，这样以前的依赖信息就会被学到。  
2、当gate是打开的时候，并不是完全替换之前的信息，而是在之前信息和现在信息之间做加权平均。所以，无论网络的深度有多深，输入序列有多长，只要gate是打开的，网络都会记住这些信息。

**LSTM如何解决梯度消失/爆炸**：   
<a href="#梯度消失和梯度爆炸">什么是梯度消失和梯度爆炸</a>  

LSTM使用门控有选择的让一部分信息通过。门控单元是由一个sigmoid单元和一个逐点乘积操作组成，sigmoid单元输出1或0，用来判断通过还是阻止，然后训练这些gate的组合。所以，当gate是打开的（梯度接近于1），梯度就不会vanish。并且sigmoid不超过1，那么梯度也不会explode。

简明数学分析：  
为了便于分析，如果考虑bias，同时忽略输入变量`$h_{j-1}$`的作用，那么隐含层之间的关系可以表示为:  
```math
c_j = \sigma(W^fX_j+b^f)c_{j-1} + \sigma(W^iX_j+b^i)\sigma(WX_j+b)
```
需要连乘的项为：
```math
\frac {\partial c_j}{c_{j-1}} = \sigma(W^fX_j+b)
```  
该值范围在0~1之间，但是在实际参数更新中，可以通过控制bias比较大，使得该值接近于1；在这种情况下，即使通过很多次连乘的操作，梯度也不会消失，仍然可以保留"长距"连乘项的存在。即总可以通过选择合适的参数，在不发生梯度爆炸的情况下，找到合理的梯度方向来更新参数，而且这个方向可以充分地考虑远距离的隐含层信息的传播影响。

---

##### GRU
> Gate Recurrent Unit，门循环单元，RNN的范畴，LSTM的变种，与LSTM一样都能保留历史记忆中的重要内容，保证在long-term中传播也能不丢失。  

"We choose to use GRU in our experiment since it performs similarly to LSTM but is computationally **cheaper**"  
简单来说，就是在实际环境下，GRU和LSTM的效果相差不大时，GRU能节省算力，提高效率，也就是能够降低成本。

![GRU](https://pic1.zhimg.com/80/v2-8134a00c243153bfd9fd2bcbe0844e9c_hd.jpg)
可以明显看出，GRU与LSTM最大区别在于每次只有一个值`$h^t$`进行传递，这样就少了几个矩阵运算，在训练数据集很大的情况下，GRU就会比LSTM节省很多时间。然而，GRU要和LSTM达到一样的效果，就需要`$h^t$`包含以前节点的记忆信息，又能生成选择性记忆的门控信号。  

这里，主要由`$h^{t-1}$`和`$x^t$`生成`$r$`(reset)和`$z$`(update)两个门控信号。  

`$r$`(reset)门控主要用来重置`$h^{t-1}$`，再与`$x^t$`进行运算，通过tanh激活函数后得到本次处理过的信息`$h^’$`。  
`$z$`(update)门控则同时兼具了遗忘和记忆的功能：`$h^{t-1}$`与`$z$`进行运算表现为遗忘之前节点信息记忆；`$h^’$`与`$1-z$`进行运算表现为选择记忆当前节点信息。  

所以，更新表达式为：`$h^t = z\cdot h^{t-1}+(1-z)\cdot h^’$` (z的范围为0~1。越接近0，对以前节点遗忘的越多，对当前节点记忆的越多；越接近1，对以前节点遗忘的越少，对当前节点记忆的越少)

---

### 其他算法
#### PCA
#### K-means 

## 常见问题

### 损失函数、代价函数、目标函数 
__首先给出结论__  
- `损失函数`和`代价函数`是同一个东西
- `目标函数`是一个与他们相关但更广的概念，对于目标函数来说在**有约束条件下的最小化**就是`损失函数(loss function)`  
![image](https://pic3.zhimg.com/v2-3f4959cd70308df496ecc4568a0d982d_r.jpg)

上面三个图的函数依次为`$f_1(x)$`, `$f_2(x)$`, `$f_3(x)$`。  
我们是想用这三个函数分别来拟合Price，Price的真实值记为`$Y$`。  

我们给定`$x$`，这三个函数都会输出一个`$f_(x)$`,这个输出的`$f_(x)$`与真实值`$Y$`可能是相同的，也可能是不同的，为了表示我们拟合的好坏，我们就用一个函数来**度量拟合的程度**，比如：`$L(Y, f(X))= (Y-f(X))^2$`，这个函数就称为`损失函数(loss function)`，或者叫`代价函数(cost function)`。  

损失函数越小，就代表模型拟合的越好。那是不是我们的目标就只是让loss function越小越好呢？还不是。
这个时候还有一个概念叫风险函数(risk function)。  

`风险函数`是**损失函数的期望**，这是由于我们输入输出的`$(X,Y)$`遵循一个联合分布，但是这个联合分布是未知的，所以无法计算。但是我们是有历史数据的，就是我们的训练集，`$f(X)$`关于训练集的平均损失称作经验风险(empirical risk)，即`$\frac{1}{N}\sum_{i=1}^\infty L(y_i,f(x_i))$`，所以我们的目标就是最小化`$\frac{1}{N}\sum_{i=1}^\infty L(y_i,f(x_i))$`，称为**经验风险最小化**。

如果到这一步就完了的话，那我们看上面的图，那肯定是最右面的`$f_3(x)$`的经验风险函数最小了，因为它对历史的数据拟合的最好嘛。但是我们从图上来看`$f_3(x)$`肯定不是最好的，因为它过度学习历史数据，导致它在真正预测时效果会很不好，这种情况称为**过拟合(over-fitting)**。  

它的函数太复杂了，都有四次方了，这就引出了下面的概念，我们不仅要让经验风险最小化，还要让结构风险最小化。这个时候就定义了一个函数`$J(f)$` ，这个函数专门用来度量模型的复杂度，在机器学习中也叫`正则化(regularization)` 。常用的有`$L1$`, `$L2$` 范数。  

到这一步我们就可以说我们最终的优化函数是：`$min\frac{1}{N}\sum_{i=1}^\infty L(y_i,f(x_i))+\lambda J(f)$` ，即最优化**经验风险**和**结构风险**，而这个函数就被称为`目标函数`。  

结合上面的例子来分析：最左面的`$f_1(x)$`结构风险最小（模型结构最简单），但是经验风险最大（对历史数据拟合的最差）；最右面的`$f_3(x)$`经验风险最小（对历史数据拟合的最好），但是结构风险最大（模型结构最复杂）;而`$f_2(x)$`达到了二者的良好平衡，最适合用来预测未知数据集。  

forward by https://www.zhihu.com/question/52398145

---
### 欠拟合和过拟合

> 欠拟合和过拟合在机器学习中经常会出现，这里总结一下出现欠拟合和过拟合的原因、情形和解决方法。

**欠拟合**  


---
<span id="梯度消失和梯度爆炸">  

### 梯度消失和梯度爆炸  
> 梯度消失的根源是：深度神经网络和反向传播  

**反向传播**：目前神经网络的优化方法大都基于反向传播的思想，即根据loss函数的误差通过梯度反向传播的方式指导深度神经网络的优化。

**梯度消失**：一般导致梯度消失的原因是在`深层网络`中使用了sigmoid等不合适的`激活函数`。  
例如：在4层的全连接网络中，第`$i$`层网络激活(`$f$`为激活函数)后的输出为`$f_i(x)$`，则`$f_{i+1}=f(f_i*w_{i+1}+b_{i+1})$`，基于梯度下降的优化策略，假设学习率为`$\alpha$`，得到参数更新为`$\Delta w=-\alpha \frac {\partial Loss}{\partial w}$`，根据链式求导法则，得到其上一层中更新梯度`$\Delta w_2=-\alpha \frac {\partial Loss}{\partial w_2}=-\alpha \frac {\partial Loss}{\partial f_4}\frac {\partial f_4}{\partial f_3}\frac {\partial f_3}{\partial f_2}\frac {\partial f_2}{\partial w_2}$`，其中`$\frac {\partial f_4}{\partial f_3}$`就是对激活函数的求导。重点来了，如果这个值`<1`，那么随着层数的增加，经过很多次乘积后，就会导致其值无限趋近于0，即梯度消失。  

**梯度爆炸**：原理同上，当激活函数求导后的值`>1`时，随着层数的增加，经过很多次乘积后，就会导致其值无限大，即梯度爆炸。

**激活函数**：根据上面的原理，当激活为sigmoid时，其倒数是恒<=0.25的，所以当网络层数很多时，很容易导致梯度消失。sigmoid的函数为：`$sigmoid(x)=\frac {1}{1+e^{-x}}$`  
另外，激活函数`$tanh(x)$`的导数恒<=1，也存在梯度消失问题。

**解决方案**：
- 使用Relu、leakRelu、elu等激活函数
- batchnorm(batch normalization)
- 残差结构
- LSTM
- 预训练加微调
- 梯度剪枝、权重正则（仅针对梯度爆炸）

---

# AI与安全

## 对抗
### 使用AI攻击目标系统
### 攻击AI系统
#### 攻击AI框架
#### 攻击AI模型
##### 对抗样本

## 防御
### 使用AI保护目标系统
#### 恶意软件检测
#### web安全检测
##### CH网络异常流量检测
### 保护AI系统
